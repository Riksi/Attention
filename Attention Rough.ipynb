{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Figure out dimensions\n",
    "- Determine if architecture will work properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2761,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with we need to create some input and output data, taking into account the fact that this data might have different lengths. Let us randomly generate some inputs and outputs. These will represent sentences which have already been processed so that words are represented by integer word ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2762,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([63, 97, 85, 31, 55, 20, 47, 67, 79]), array([23, 88, 88, 37, 82, 83, 68]), array([28, 29, 45,  7, 19,  8, 13, 12]), array([67, 10, 59, 67, 72, 67]), array([ 1, 46, 19, 62, 40, 86, 47, 18,  9]), array([38, 49, 85, 93, 95, 80, 53, 98]), array([83, 19, 15, 14, 63, 59]), array([16, 19, 28, 31, 90]), array([47, 99, 81, 30, 54, 51, 23, 86]), array([ 4, 48, 24,  1,  7, 93, 65, 18, 13, 20])]\n",
      "[array([85, 79, 44, 81,  5, 44, 13, 33]), array([61, 35, 47, 52, 67, 37]), array([94, 95, 17, 61, 26, 19,  4]), array([13, 14, 58, 62, 82]), array([33, 66, 62, 47, 86, 14, 94]), array([97, 17, 82, 99, 24]), array([44, 75, 76, 22, 16, 62, 45, 85]), array([31, 70, 27, 87, 97]), array([ 7, 42, 59, 31, 32, 57, 66]), array([17, 92, 17, 76, 16, 48,  2, 38, 27, 19])]\n"
     ]
    }
   ],
   "source": [
    "inputs = [np.random.randint(1,100,n) for n in  np.random.randint(5,11,10)]\n",
    "outputs = [np.random.randint(1,100,n) for n in  np.random.randint(5,11,10)]\n",
    "\n",
    "print(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For use in the RNN, let us calculate sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2763,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7, 8, 6, 9, 8, 6, 5, 8, 10] [8, 6, 7, 5, 7, 5, 8, 5, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "input_lens = list(map(len,inputs))\n",
    "output_lens = list(map(len,outputs))\n",
    "\n",
    "print(input_lens, output_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to run a bidirectional RNN and get all the states. We will use tensorflow's birectional_dynamic_RNN for this purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us define placeholder for the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2764,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2765,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2766,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(dtype=tf.int32,shape=[batch_size,None])\n",
    "seq_lens = tf.placeholder(dtype=tf.int32,shape=[batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2767,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tf.placeholder(dtype=tf.float32,shape=[batch_size,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look up embeddings for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2768,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_vocab_size = 100\n",
    "target_vocab_size = 100\n",
    "embed_size = 20\n",
    "hidden_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2769,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_embeddings = tf.get_variable('source_embedding_matrix',\n",
    "                            [source_vocab_size+1, embed_size])\n",
    "encoder_inputs = tf.nn.embedding_lookup(source_embeddings, input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use GRU cells for both directions of the RNN and use tensorflow's bidirectional_dynamic_rnn dynamically unroll the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2770,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_fw_cell = tf.contrib.rnn.GRUCell(hidden_size)\n",
    "enc_bw_cell = tf.contrib.rnn.GRUCell(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2771,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out, states = \\\n",
    "tf.nn.bidirectional_dynamic_rnn(cell_fw = enc_fw_cell, \n",
    "                                         cell_bw = enc_bw_cell,\n",
    "                                         inputs = encoder_inputs,\n",
    "                                         sequence_length = seq_lens,\n",
    "                                         dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2772,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concat_outputs = tf.concat(out, 2) #F in the pseudo-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this is not much different from running an ordinary RNN as you might do for a language modelling task. However now we need to implement a decoder with attention. Whilst tensorflow has functions that can simplify this process, let us go through it step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to calculate an initial state for the decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensions of the different matrices.\n",
    "\n",
    "- X - batch_size x max_sequence_length\n",
    "- rnn_inputs - batch_size x max_sequence_length x source_embed_size\n",
    "- Each output - batch_size x max_sequence_length x encoder_state_size\n",
    "- F = concat_outputs - batch_size x (max_sequence_length\\*2) x encoder_state_size\n",
    "- U - encoder_state_size x decoder_state_size\n",
    "- bw_output1 - batch_size x encoder_state_size\n",
    "\n",
    "- s_0 = decoder_state = tf.matmul(U,tf.transpose(bw_output1))\n",
    "\n",
    "- s_0 = decoder_state - batch_size x decoder_state_size\n",
    "\n",
    "- W - [dim] x (max_sequence_length\\*2)\n",
    "\n",
    "- X - batch_size x [dim] x encoder_state_size\n",
    "\n",
    "- V - [dim] x \n",
    "\n",
    "\n",
    "- c_t - batch_size x target_embed_size\n",
    "- P - vocab_size x decoder_state_size\n",
    "- b - vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2773,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(None), Dimension(25)])"
      ]
     },
     "execution_count": 2773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[-1].get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2774,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bw_output1 = out[-1][:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2775,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 25]"
      ]
     },
     "execution_count": 2775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw_output1.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2776,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U = tf.get_variable('U',[hidden_size,hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2777,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "padded_inputs = np.array([np.concatenate((i,\n",
    "            [0 for j in range(10-len(i))])) for i in inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2778,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 63.,  97.,  85.,  31.,  55.,  20.,  47.,  67.,  79.,   0.],\n",
       "       [ 23.,  88.,  88.,  37.,  82.,  83.,  68.,   0.,   0.,   0.],\n",
       "       [ 28.,  29.,  45.,   7.,  19.,   8.,  13.,  12.,   0.,   0.],\n",
       "       [ 67.,  10.,  59.,  67.,  72.,  67.,   0.,   0.,   0.,   0.],\n",
       "       [  1.,  46.,  19.,  62.,  40.,  86.,  47.,  18.,   9.,   0.],\n",
       "       [ 38.,  49.,  85.,  93.,  95.,  80.,  53.,  98.,   0.,   0.],\n",
       "       [ 83.,  19.,  15.,  14.,  63.,  59.,   0.,   0.,   0.,   0.],\n",
       "       [ 16.,  19.,  28.,  31.,  90.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [ 47.,  99.,  81.,  30.,  54.,  51.,  23.,  86.,   0.,   0.],\n",
       "       [  4.,  48.,  24.,   1.,   7.,  93.,  65.,  18.,  13.,  20.]])"
      ]
     },
     "execution_count": 2778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2779,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_array = 1.0*(padded_inputs[:2]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2780,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    U_,bw_ = sess.run([U,bw_output1],\n",
    "                      feed_dict={input_ids: padded_inputs[:2],\n",
    "                                 mask: mask_array,\n",
    "                                 seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2781,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 25), (2, 25))"
      ]
     },
     "execution_count": 2781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_.shape, bw_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will unroll the decoder network. We will do so for 1 plus the maximum sequence length of the outputs. The reason for the 1 plus the maximum length is that each input will have a special ``<GO>`` symbol at the start. So the target embedding matrix has an additional embedding for this symbol. The reason that the embedding matrix has target_vocab_size + 2 is to account for the fact we zero-pad inputs. Thus we need to ensure that there is a different id for ``<GO>`` so that it gets a different embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2782,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_state = tf.matmul(bw_output1,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2783,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    d_ = sess.run(decoder_state,feed_dict={input_ids: padded_inputs[:2], seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2784,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 25)"
      ]
     },
     "execution_count": 2784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2785,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_embeddings = tf.get_variable('target_embedding_matrix',\n",
    "                            [target_vocab_size+2, embed_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a placeholder for the inputs. This will consist of a batch of embeddings for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2786,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_input = tf.placeholder(tf.int32,[batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2787,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_output = tf.placeholder(tf.int32,[batch_size,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2788,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "decoder_length = max(output_lens)\n",
    "print(decoder_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2789,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "align_dim = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2790,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.get_variable('W',[1,2*hidden_size,align_dim],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2791,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_rep = tf.tile(W,[2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2792,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.matmul(concat_outputs,W_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2793,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    c_,W_,Wr_,X_ = sess.run([concat_outputs,W,W_rep,X],feed_dict={input_ids: padded_inputs[:2], seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2794,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 10, 50), (1, 50, 15), (2, 50, 15), (2, 10, 15))"
      ]
     },
     "execution_count": 2794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_.shape, W_.shape,Wr_.shape, X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2795,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V = tf.get_variable('V',[hidden_size,align_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2796,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_t = tf.matmul(decoder_state,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2797,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    r_ = sess.run(r_t,feed_dict={input_ids: padded_inputs[:2], seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2798,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 15)"
      ]
     },
     "execution_count": 2798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2799,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tanh_input = X + tf.expand_dims(r_t,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2800,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    X_,r_,ti = sess.run([X,r_t,tanh_input],\n",
    "                        feed_dict={input_ids: padded_inputs[:2], seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the calculation for $WF$ in advance as it does not depend on the output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2801,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01032581,  0.05872528,  0.03408724,  0.05432902,  0.10617474,\n",
       "        -0.05815943,  0.0832762 ,  0.00407253,  0.02143284,  0.10079458,\n",
       "         0.00548378, -0.01343164,  0.01918724, -0.06038353,  0.00208974], dtype=float32),\n",
       " array([ 0.01032581,  0.05872528,  0.03408724,  0.05432902,  0.10617474,\n",
       "        -0.05815942,  0.0832762 ,  0.00407253,  0.02143284,  0.10079458,\n",
       "         0.00548378, -0.01343164,  0.01918724, -0.06038353,  0.00208974], dtype=float32))"
      ]
     },
     "execution_count": 2801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti[0][0]-r_[0],X_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2802,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 10, 15), (2, 15), (2, 10, 15))"
      ]
     },
     "execution_count": 2802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.shape,r_.shape,X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2803,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.get_variable('v',[1,align_dim,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2804,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_rep = tf.tile(v,[2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2805,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_t = tf.matmul(tanh_input,v_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2806,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_t = tf.squeeze(u_t,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2807,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    u_,v_,vr_ = sess.run([u_t,v,v_rep],\n",
    "                        feed_dict={input_ids: padded_inputs[:2], seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2808,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 10), (1, 15, 1), (2, 15, 1))"
      ]
     },
     "execution_count": 2808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_.shape,v_.shape,vr_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2809,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_u_t = tf.exp(u_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2810,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "softmax_denom = tf.reduce_sum(exp_u_t*mask,axis=1,keep_dims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2811,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_t = exp_u_t/softmax_denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2812,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_t = a_t*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2813,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    a_ = sess.run(a_t,\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2814,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 2814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2815,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 50)"
      ]
     },
     "execution_count": 2815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2816,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 25)"
      ]
     },
     "execution_count": 2816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2817,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_expn = tf.expand_dims(a_t,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2818,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_t = tf.matmul(a_expn,concat_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2819,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_t = tf.squeeze(c_t,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2820,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    ax_,ct_ = sess.run([a_expn,c_t],\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   seq_lens:input_lens[:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2821,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1, 10), (2, 50))"
      ]
     },
     "execution_count": 2821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_.shape,ct_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a cell for the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2822,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.GRUCell(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2823,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_embed = tf.nn.embedding_lookup(target_embeddings, tf.zeros([batch_size],tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2824,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "padded_outputs = np.array([np.concatenate((i,\n",
    "            [0 for j in range(10-len(i))])) for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2825,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_lens_out = tf.placeholder(dtype=tf.int32,shape=[batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2826,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    dec_em = sess.run(decoder_embed,\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   target_input:padded_outputs[:2][:,1], \n",
    "                                   seq_lens:input_lens[:2],\n",
    "                                   seq_lens_out:output_lens[:2],\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2827,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "execution_count": 2827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_em.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2828,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_input = tf.concat([decoder_embed,c_t],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2829,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"RNN\"):\n",
    "    decoder_state_t, _ = decoder_cell(inputs=decoder_input,\n",
    "                                  state=decoder_state) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2830,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    di_,dst_ = sess.run([decoder_input,decoder_state_t],\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   target_input:padded_outputs[:2], \n",
    "                                   seq_lens:input_lens[:2],\n",
    "                                   target_input:padded_outputs[:2][:,0],\n",
    "                                   seq_lens_out:output_lens[:2],\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2831,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 70), (2, 25))"
      ]
     },
     "execution_count": 2831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di_.shape, dst_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2832,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = tf.get_variable('P',[hidden_size,target_vocab_size+2])\n",
    "b = tf.get_variable('b',[target_vocab_size+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a mask so that outputs at points beyond the maximum sequence length are not taken into consideration when calculating loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2833,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2834,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_t = tf.nn.softmax(tf.matmul(decoder_state_t,P)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2835,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    y_ = sess.run(y_t,\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   target_input:padded_outputs[:2], \n",
    "                                   seq_lens:input_lens[:2],\n",
    "                                   target_input:padded_outputs[:2][:,0],\n",
    "                                   seq_lens_out:output_lens[:2],\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2836,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(102)])"
      ]
     },
     "execution_count": 2836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2837,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onehot = tf.one_hot(target_output[:,0],depth=target_vocab_size+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2838,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_t = tf.argmax(y_t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2839,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    em_t,oh_,to_ = sess.run([embed_t,onehot,target_output],\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   target_input:padded_outputs[:2], \n",
    "                                   seq_lens:input_lens[:2],\n",
    "                                   target_input:padded_outputs[:2][:,0],\n",
    "                                   seq_lens_out:output_lens[:2],\n",
    "                                   target_output:np.concatenate((np.zeros((1,9)),\n",
    "                                                               np.ones((1,9))))\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2840,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([52, 52]),\n",
       " array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32),\n",
       " array([0, 1], dtype=int32))"
      ]
     },
     "execution_count": 2840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_t, oh_,to_[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2841,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits =tf.matmul(decoder_state_t,P)+b,\n",
    "                        labels = onehot\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2842,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses.append(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    xe_= sess.run(cross_entropy,\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   target_input:padded_outputs[:2], \n",
    "                                   seq_lens:input_lens[:2],\n",
    "                                   target_input:padded_outputs[:2][:,0],\n",
    "                                   seq_lens_out:output_lens[:2],\n",
    "                                   target_output:np.concatenate((np.ones((1,9)),\n",
    "                                                               np.zeros((1,9))))\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.72140074,  4.75428104], dtype=float32)"
      ]
     },
     "execution_count": 2844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2845,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_t2 = tf.matmul(decoder_state,V)\n",
    "\n",
    "u_t2 = tf.matmul(tanh_input,v_rep)\n",
    "u_t2 = tf.squeeze(u_t2,axis=2)\n",
    "\n",
    "exp_u_t2 = tf.exp(u_t2)\n",
    "softmax_denom = tf.reduce_sum(exp_u_t2*mask,axis=1,keep_dims=True)\n",
    "a_t2 = exp_u_t2/softmax_denom\n",
    "a_t2 = a_t2*mask\n",
    "\n",
    "a_expn2 = tf.expand_dims(a_t2,axis=1)\n",
    "c_t2 = tf.matmul(a_expn2,concat_outputs)\n",
    "c_t2 = tf.squeeze(c_t2,axis=1)\n",
    "\n",
    "decoder_input2 = tf.concat([tf.nn.embedding_lookup(target_embeddings,embed_t),\n",
    "                            c_t2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2846,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"RNN\", reuse=True):\n",
    "    decoder_state_t2, _ = decoder_cell(inputs=  decoder_input2,\n",
    "                                      state=decoder_state_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2847,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_t2 = tf.nn.softmax(tf.matmul(decoder_state_t2,P)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2848,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    y2_ = sess.run(y_t2,\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   target_input:padded_outputs[:2], \n",
    "                                   seq_lens:input_lens[:2],\n",
    "                                   target_input:padded_outputs[:2][:,0],\n",
    "                                   seq_lens_out:output_lens[:2],\n",
    "                                   target_output:padded_outputs[:2][:,1:]\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2849,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 102)"
      ]
     },
     "execution_count": 2849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2850,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot2 = tf.one_hot(target_output[:,1],depth=target_vocab_size+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2851,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy2 = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits = tf.matmul(decoder_state_t2,P)+b,\n",
    "                        labels = onehot\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2852,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses.append(cross_entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2853,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_mask = tf.placeholder(dtype=tf.float32,shape=[batch_size,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2854,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "losses = [tf.expand_dims(loss,axis=1) for loss in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2857,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_mat = tf.concat(losses,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2858,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_loss = tf.reduce_sum(loss_mat*target_mask)/tf.reduce_sum(target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2861,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    oh2_,xe2_,av_,lm_ = sess.run([onehot2,cross_entropy2,avg_loss,loss_mat],\n",
    "                        feed_dict={input_ids: padded_inputs[:2], \n",
    "                                   mask:mask_array,\n",
    "                                   target_input:padded_outputs[:2], \n",
    "                                   seq_lens:input_lens[:2],\n",
    "                                   target_input:padded_outputs[:2][:,0],\n",
    "                                   seq_lens_out:output_lens[:2],\n",
    "                                   target_output:np.concatenate((np.zeros((1,9)),\n",
    "                                                               np.ones((1,9)))),\n",
    "                                   target_mask:np.array([[1,0],[1,1]])\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2862,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32),\n",
       " array([ 4.72140074,  4.75428104], dtype=float32),\n",
       " array([ 4.54834461,  4.61919928], dtype=float32),\n",
       " 4.5969563,\n",
       " array([[ 4.55945015,  4.54834461],\n",
       "        [ 4.61221933,  4.61919928]], dtype=float32))"
      ]
     },
     "execution_count": 2862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " oh2_,xe_,xe2_,av_,lm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2759,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2759-aec13b5efb2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxe_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxe2_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (2,2) "
     ]
    }
   ],
   "source": [
    "np.sum(np.vstack((xe_,xe2_))*np.array([[1,0],[1,1]]))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in range(decoder_length):\n",
    "    decoder_embed = tf.nn.embedding_lookup(target_embeddings, target_input)\n",
    "    logits = []\n",
    "    if t > 0:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        r_t = tf.matmul(V, decoder_state)\n",
    "        u_t = tf.matmul(v, tf.tanh(X + r_t))\n",
    "        a_t = tf.nn.softmax(u_t)\n",
    "        c_t = tf.matmul(concat_outputs,a_t)\n",
    "        decoder_input = tf.concat([decoder_embed,c_t])\n",
    "        decoder_state, _ = decoder_cell(decoder_input,decoder_state) \n",
    "        #tf's RNNCell classes return two outputs out and state \n",
    "        #but for the GRUCell these are the same\n",
    "        \n",
    "        logit = tf.nn.softmax(tf.nn.xw_plus_b(decoder_state,P,b))\n",
    "        logits.append(tf.argmax(logit, 1))\n",
    "        onehot = tf.one_hot(decoder_output,depth=target_vocab_size+2)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                        logits = logit,\n",
    "                        label = onehot\n",
    "                    )\n",
    "        loss = tf.reduce_sum(cross_entropy)\n",
    "\n",
    "        total_loss += loss\n",
    "    total_loss = total_loss / tf.reduce_sum(mask[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = encode_as_matrix(f)\n",
    "embed = '<START>' #e_0\n",
    "U = tf.get_variable('U',[hid_dim,inp_dim])\n",
    "V = tf.get_variable('V',[])\n",
    "W = tf.get_variable('W',[])\n",
    "P = tf.get_variable('P',[])\n",
    "\n",
    "X = tf.matmul(W,F)\n",
    "state = tf.xw_plus_b(U,h_1)\n",
    "RNN = tf.contrib.rnn.RNNCell\n",
    "while embed != '<END>': #e_t\n",
    "    t = t + 1\n",
    "    r_t = tf.matmul(V,state)\n",
    "    u_t = tf.matmul(v,tf.tanh(X + r_t))\n",
    "    a_t = tf.nn.softmax(u_t)\n",
    "    c_t = tf.matmul(F,a_t)\n",
    "    hidden = RNN(hidden,tf.concat([embed,c_t],axis=0)) #s_t\n",
    "    y_t = tf.nn.softmax(tf.matmul(P,hidden)+b)\n",
    "    distr = tf.contrib.distributions.Categorical(p=y_t)\n",
    "    e_t = distr.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_fw_cell.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
